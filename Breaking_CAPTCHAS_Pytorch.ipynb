{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb2thjvfIJx3usQ9iZz5Xm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annapetrbok/ee467wi2026/blob/main/Breaking_CAPTCHAS_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "20MwFsobHack"
      },
      "outputs": [],
      "source": [
        "import os, cv2, numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "import os, pickle, glob, math\n",
        "from pprint import pprint\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lab_2_helpers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset images folder\n",
        "CAPTCHA_IMAGE_FOLDER = \"./captcha-images\"\n",
        "\n",
        "# List of all the captcha images we need to process\n",
        "captcha_image_paths = list(paths.list_images(CAPTCHA_IMAGE_FOLDER))\n",
        "# Review image paths\n",
        "pprint(captcha_image_paths[:10])\n",
        "\n",
        "!tar -xJf captcha-images.tar.xz\n",
        "!ls -la\n",
        "!find . -maxdepth 2 -type d | sed -n '1,120p'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kQyOcrFPiC6",
        "outputId": "db1c409c-58ad-4e76-f1d5-a6c9e29d005a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./captcha-images/J3NJ.png',\n",
            " './captcha-images/2QRH.png',\n",
            " './captcha-images/E7ZC.png',\n",
            " './captcha-images/2GHE.png',\n",
            " './captcha-images/L4M9.png',\n",
            " './captcha-images/M4YZ.png',\n",
            " './captcha-images/M4PD.png',\n",
            " './captcha-images/8CRP.png',\n",
            " './captcha-images/C4NZ.png',\n",
            " './captcha-images/M4BT.png']\n",
            "total 1080\n",
            "drwxr-xr-x 1 root root    4096 Jan 30 18:58 .\n",
            "drwxr-xr-x 1 root root    4096 Jan 30 18:46 ..\n",
            "drwxr-xr-x 2 1000 1000   32768 Dec 15  2017 captcha-images\n",
            "-rw-r--r-- 1 root root 1044556 Jan 30 18:55 captcha-images.tar.xz\n",
            "drwxr-xr-x 4 root root    4096 Jan 16 14:24 .config\n",
            "-rw-r--r-- 1 root root    3603 Jan 30 18:51 lab_2_helpers.py\n",
            "drwxr-xr-x 2 root root    4096 Jan 30 18:55 __pycache__\n",
            "drwxr-xr-x 1 root root    4096 Jan 16 14:24 sample_data\n",
            ".\n",
            "./.config\n",
            "./.config/configurations\n",
            "./.config/logs\n",
            "./__pycache__\n",
            "./captcha-images\n",
            "./sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lab_2_helpers import resize_to_fit  # you already have lab_2_helpers.py\n",
        "\n",
        "# --- settings ---\n",
        "TVT_SPLIT_SEED = 31528476\n",
        "CAPTCHA_IMAGE_FOLDER = \"./captcha-images\"\n",
        "CHAR_IMAGE_FOLDER = f\"./char-images-{TVT_SPLIT_SEED}\"\n",
        "FORCE_EXTRACT_CHAR = True  # set False if you want to reuse if already exists\n",
        "\n",
        "# --- load captcha paths + texts from filenames ---\n",
        "captcha_image_paths = list(paths.list_images(CAPTCHA_IMAGE_FOLDER))\n",
        "\n",
        "def extract_captcha_text(image_path):\n",
        "    image_file_name = os.path.basename(image_path)\n",
        "    return os.path.splitext(image_file_name)[0]\n",
        "\n",
        "captcha_texts = [extract_captcha_text(p) for p in captcha_image_paths]\n",
        "\n",
        "# --- load + grayscale + padding (same as TF) ---\n",
        "def load_transform_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image_padded = cv2.copyMakeBorder(image_gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "    return image_padded\n",
        "\n",
        "captcha_images = [load_transform_image(p) for p in captcha_image_paths]\n",
        "\n",
        "# --- train/val vs test split (same seed) ---\n",
        "captcha_images_tv, captcha_images_test, captcha_texts_tv, captcha_texts_test = train_test_split(\n",
        "    captcha_images, captcha_texts, test_size=0.2, random_state=TVT_SPLIT_SEED, shuffle=True\n",
        ")\n",
        "\n",
        "print(\"Train-validation:\", len(captcha_texts_tv))\n",
        "print(\"Test:\", len(captcha_texts_test))\n",
        "\n",
        "# --- segmentation functions (same as TF) ---\n",
        "def extract_chars(image):\n",
        "    image_bw = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "    contours = cv2.findContours(image_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "\n",
        "    char_regions = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        if w / h > 1.25:\n",
        "            half_width = int(w / 2)\n",
        "            char_regions.append((x, y, half_width, h))\n",
        "            char_regions.append((x + half_width, y, half_width, h))\n",
        "        else:\n",
        "            char_regions.append((x, y, w, h))\n",
        "\n",
        "    if len(char_regions) != 4:\n",
        "        return None\n",
        "\n",
        "    char_regions.sort(key=lambda x: x[0])\n",
        "\n",
        "    char_images = []\n",
        "    for x, y, w, h in char_regions:\n",
        "        # safe slicing (padding usually prevents issues, but clamp anyway)\n",
        "        x0 = max(x - 2, 0); y0 = max(y - 2, 0)\n",
        "        x1 = min(x + w + 2, image.shape[1]); y1 = min(y + h + 2, image.shape[0])\n",
        "        char_images.append(image[y0:y1, x0:x1])\n",
        "\n",
        "    return char_images\n",
        "\n",
        "def save_chars(char_images, captcha_text, save_dir, char_counts):\n",
        "    for char_image, char in zip(char_images, captcha_text):\n",
        "        save_path = os.path.join(save_dir, char)\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        char_count = char_counts.get(char, 1)\n",
        "        char_image_path = os.path.join(save_path, f\"{char_count}.png\")\n",
        "        cv2.imwrite(char_image_path, char_image)\n",
        "        char_counts[char] = char_count + 1\n",
        "\n",
        "# --- run extraction ---\n",
        "if FORCE_EXTRACT_CHAR or not os.path.exists(CHAR_IMAGE_FOLDER):\n",
        "    # if folder exists but empty, also rebuild\n",
        "    if os.path.exists(CHAR_IMAGE_FOLDER):\n",
        "        # optional: clear it to avoid mixing partial runs\n",
        "        import shutil\n",
        "        shutil.rmtree(CHAR_IMAGE_FOLDER)\n",
        "\n",
        "    char_counts = {}\n",
        "    os.makedirs(CHAR_IMAGE_FOLDER, exist_ok=True)\n",
        "\n",
        "    n_saved = 0\n",
        "    n_skipped = 0\n",
        "    for img, text in zip(captcha_images_tv, captcha_texts_tv):\n",
        "        chars = extract_chars(img)\n",
        "        if chars is None:\n",
        "            n_skipped += 1\n",
        "            continue\n",
        "        save_chars(chars, text, CHAR_IMAGE_FOLDER, char_counts)\n",
        "        n_saved += 1\n",
        "\n",
        "    print(\"CAPTCHAs processed:\", len(captcha_images_tv))\n",
        "    print(\"Saved (segmented OK):\", n_saved)\n",
        "    print(\"Skipped (seg failed):\", n_skipped)\n",
        "\n",
        "# --- verify ---\n",
        "from imutils import paths as ipaths\n",
        "print(\"Character images now found:\", len(list(ipaths.list_images(CHAR_IMAGE_FOLDER))))\n",
        "print(\"Sample paths:\", list(ipaths.list_images(CHAR_IMAGE_FOLDER))[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqvjtwlLPTx6",
        "outputId": "b40f144b-ae75-4908-95df-1ff7b4a700af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-validation: 908\n",
            "Test: 228\n",
            "CAPTCHAs processed: 908\n",
            "Saved (segmented OK): 892\n",
            "Skipped (seg failed): 16\n",
            "Character images now found: 3568\n",
            "Sample paths: ['./char-images-31528476/X/26.png', './char-images-31528476/X/39.png', './char-images-31528476/X/22.png', './char-images-31528476/X/49.png', './char-images-31528476/X/42.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "CHAR_IMAGE_FOLDER = \"./char-images-31528476\"\n",
        "\n",
        "classes = sorted([\n",
        "    d for d in os.listdir(CHAR_IMAGE_FOLDER)\n",
        "    if os.path.isdir(os.path.join(CHAR_IMAGE_FOLDER, d))\n",
        "])\n",
        "print(\"n_classes:\", len(classes), \"| sample:\", classes[:10])\n",
        "\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
        "n_classes = len(classes)\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, paths_list, class_to_idx):\n",
        "        self.paths = paths_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (20, 20), interpolation=cv2.INTER_AREA)\n",
        "        x = torch.tensor(img, dtype=torch.float32).unsqueeze(0) / 255.0\n",
        "        y = self.class_to_idx[path.split(os.path.sep)[-2]]\n",
        "        return x, y\n",
        "\n",
        "all_paths = list(paths.list_images(CHAR_IMAGE_FOLDER))\n",
        "train_paths, val_paths = train_test_split(all_paths, test_size=0.25, random_state=955996, shuffle=True)\n",
        "\n",
        "train_loader = DataLoader(CharDataset(train_paths, class_to_idx), batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(CharDataset(val_paths, class_to_idx), batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"train chars:\", len(train_paths), \"| val chars:\", len(val_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9y_9hJLHeXc",
        "outputId": "fead7209-989b-4dc6-a07a-4c4dfec95a34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "n_classes: 32 | sample: ['2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B']\n",
            "train chars: 2676 | val chars: 892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CaptchaCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 20, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(20, 50, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(50*5*5, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.conv(x))\n",
        "\n",
        "model = CaptchaCNN(n_classes).to(device)\n"
      ],
      "metadata": {
        "id": "QYzNJUzhH7_l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | val_acc = {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "3-HYiV8FH_Rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4ddaea-c5d2-484d-806b-e024f2872464"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | val_acc = 0.9103\n",
            "Epoch 02 | val_acc = 0.9798\n",
            "Epoch 03 | val_acc = 0.9899\n",
            "Epoch 04 | val_acc = 0.9933\n",
            "Epoch 05 | val_acc = 0.9933\n",
            "Epoch 06 | val_acc = 0.9933\n",
            "Epoch 07 | val_acc = 0.9933\n",
            "Epoch 08 | val_acc = 0.9933\n",
            "Epoch 09 | val_acc = 0.9933\n",
            "Epoch 10 | val_acc = 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "# ---- helper: make a (1,20,20) tensor from a single char image ----\n",
        "def make_char_tensor(char_img):\n",
        "    # char_img is a 2D grayscale numpy array\n",
        "    img = cv2.resize(char_img, (20, 20), interpolation=cv2.INTER_AREA)\n",
        "    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0) / 255.0  # (1,20,20)\n",
        "    return x\n",
        "\n",
        "# ---- build a flat list of character tensors for ALL test CAPTCHAs ----\n",
        "extract_failed_indices = []\n",
        "char_tensors = []\n",
        "\n",
        "for i, captcha_img in enumerate(captcha_images_test):\n",
        "    chars = extract_chars(captcha_img)  # should return list of 4 images or None\n",
        "    if chars is None:\n",
        "        extract_failed_indices.append(i)\n",
        "        # add 4 dummy chars (won't matter; we will overwrite result with \"-\")\n",
        "        for _ in range(4):\n",
        "            char_tensors.append(torch.zeros((1, 20, 20), dtype=torch.float32))\n",
        "    else:\n",
        "        for ch in chars:\n",
        "            char_tensors.append(make_char_tensor(ch))\n",
        "\n",
        "# Stack into one batch: (N_chars, 1, 20, 20)\n",
        "X_test_chars = torch.stack(char_tensors, dim=0)\n",
        "\n",
        "# ---- run model prediction ----\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test_chars.to(device))\n",
        "    pred_idx = logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# Convert predicted indices to characters\n",
        "pred_chars = [idx_to_class[i] for i in pred_idx]\n",
        "\n",
        "# Group every 4 predicted characters into a CAPTCHA string\n",
        "pred_texts = [\"\".join(pred_chars[i:i+4]) for i in range(0, len(pred_chars), 4)]\n",
        "\n",
        "# Overwrite CAPTCHAs where extraction failed\n",
        "for i in extract_failed_indices:\n",
        "    pred_texts[i] = \"-\"\n",
        "\n",
        "# ---- compute CAPTCHA accuracy ----\n",
        "n_test = len(captcha_texts_test)\n",
        "n_correct = sum(p == t for p, t in zip(pred_texts, captcha_texts_test))\n",
        "\n",
        "print(\"# of test CAPTCHAs:\", n_test)\n",
        "print(\"# correctly recognized:\", n_correct)\n",
        "print(\"Accuracy:\", n_correct / n_test)\n",
        "print(\"Extraction failed (marked '-'):\", len(extract_failed_indices))\n"
      ],
      "metadata": {
        "id": "jg-KWp-lIDcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0957205f-fd1f-4f8b-ef97-8c1a1e8706b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of test CAPTCHAs: 228\n",
            "# correctly recognized: 219\n",
            "Accuracy: 0.9605263157894737\n",
            "Extraction failed (marked '-'): 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PyTorch results: CAPTCHA test accuracy = 0.9605 (219/228).\n",
        "#TensorFlow results: CAPTCHA test accuracy â‰ˆ 0.9386 (214/228).\n",
        "#The differences are due to the randomness, initialization, and implementation details. Both frameworks achieve similar performance."
      ],
      "metadata": {
        "id": "xy3ZnOYUIEC0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}